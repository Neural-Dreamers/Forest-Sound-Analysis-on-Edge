{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3622,"status":"ok","timestamp":1699206172996,"user":{"displayName":"Dakshina Ranmal","userId":"07815065643648254868"},"user_tz":-330},"id":"l7xq474RxVAo","outputId":"1755cbca-8ed4-4557-dfea-8fac4533d23d"},"outputs":[],"source":["import pandas as pd\n","import os\n","import zipfile\n","import numpy as np\n","import gc\n","import pickle\n","import warnings\n","import tensorflow as tf\n","import tensorflow_model_optimization as tfmot\n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{},"source":["Import dataset pickle file"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1699206219194,"user":{"displayName":"Dakshina Ranmal","userId":"07815065643648254868"},"user_tz":-330},"id":"xjiawRRYy3bi"},"outputs":[],"source":["def get_pickle(pickle_dir, file_name):\n","    pickle_dir = os.path.join(os.getcwd(), 'datasets/fsc22/Pickle Files/' + pickle_dir)\n","    fold_dir = os.path.join(pickle_dir, file_name)\n","    infile = open(fold_dir, 'rb')\n","    fold = pickle.load(infile)\n","    infile.close()\n","\n","    return fold"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":30499,"status":"ok","timestamp":1699206250223,"user":{"displayName":"Dakshina Ranmal","userId":"07815065643648254868"},"user_tz":-330},"id":"7_vT-2D8y4th"},"outputs":[],"source":["with tf.device('/CPU:0'):\n","    pickle_dir = 'aug_ts_ps_mixed_features_5_20_5fold' # change pickle file directory name accordingly\n","    \n","    spect_folds = []\n","    train_spects = []\n","    \n","    for fold in range(5):\n","        spects_fold = get_pickle(pickle_dir, pickle_dir + '_fold' + str(fold+1))\n","        train_spects.extend(spects_fold)\n","        spect_folds.append(spects_fold)\n","\n","    print(f'len train_spects: {len(train_spects)}')\n","\n","    train_features_df = pd.DataFrame(train_spects, columns=['feature', 'class'])\n","\n","    del train_spects\n","\n","    gc.collect()\n","    \n","    print(f'len spect_folds: {len(spect_folds)}') # num folds\n","    print(f'len spect_folds[0]: {len(spect_folds[0])}') # samples in a fold\n","    print(f'len spect_folds[0][0]: {len(spect_folds[0][0])}') # elements in a sample - should be 2\n","    print(f'shape spect_folds[0][0][0]: {np.shape(spect_folds[0][0][0])}') # spectrogram shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2858,"status":"ok","timestamp":1699206253076,"user":{"displayName":"Dakshina Ranmal","userId":"07815065643648254868"},"user_tz":-330},"id":"rkpuAgdTy-MK"},"outputs":[],"source":["with tf.device('/CPU:0'):\n","    IMG_SIZE = (spect_folds[0][0][0].shape[0], spect_folds[0][0][0].shape[1])\n","    IMG_SHAPE = IMG_SIZE + (3,)\n","    print(IMG_SHAPE)\n","    input_shape = IMG_SHAPE\n","\n","    num_labels = 26 # Should be changed"]},{"cell_type":"markdown","metadata":{},"source":["Import base model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7149,"status":"ok","timestamp":1699206260213,"user":{"displayName":"Dakshina Ranmal","userId":"07815065643648254868"},"user_tz":-330},"id":"FvR9NobG0G3q","outputId":"7a738a83-20db-4579-b8b1-ef4886fc34fe"},"outputs":[],"source":["with tf.device('/CPU:0'):\n","    valid_model_type = False\n","    model_type = None\n","\n","    while not valid_model_type:\n","        model_type = input(\n","            \"Choose Model Type:\\n\"\n","            \" 1. AlexNet\\n\"\n","            \" 2. DenseNet121\\n\"\n","            \" 3. EfficientNetV2B0\\n\"\n","            \" 4. InceptionV3\\n\"\n","            \" 5. MobileNetV3Small\\n\"\n","            \" 6. ResNet50V2\\n\"\n","            \" 7. SqueezeNet\\n :\")\n","\n","        if model_type == '1':\n","            model_type = 'AlexNet'\n","            valid_model_type = True\n","        elif model_type =='2':\n","            model_type = 'DenseNet121'\n","            valid_model_type = True\n","        elif model_type =='3':\n","            model_type = 'EfficientNetV2B0'\n","            valid_model_type = True\n","        elif model_type =='4':\n","            model_type = 'InceptionV3'\n","            valid_model_type = True\n","        elif model_type =='5':\n","            model_type = 'MobileNetV3-Small'\n","            valid_model_type = True\n","        elif model_type =='6':\n","            model_type = 'ResNet50V2'\n","            valid_model_type = True\n","        elif model_type =='7':\n","            model_type = 'SqueezeNet'\n","            valid_model_type = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45733,"status":"ok","timestamp":1699206305937,"user":{"displayName":"Dakshina Ranmal","userId":"07815065643648254868"},"user_tz":-330},"id":"GqjDtJ9-6p3O","outputId":"c01827e3-28f7-425a-aa2a-f7f2a24574ef"},"outputs":[],"source":["with tf.device('/CPU:0'):\n","    models_dir = os.path.join(os.getcwd(), \"models\")\n","    model_dir = os.path.join(models_dir, model_type)\n","\n","    # Example - \n","    # model_name = 'DenseNet_aug5_mix_5fold'\n","    # base_model_save_path = 'models/DenseNet121/DenseNet_aug5_mix_5fold/DenseNet_aug5_mix_5fold_base_fold1.h5'\n","    # fold_no = 1\n","    \n","    model_name = input('Enter model name: ')\n","    base_model_save_path = input('Enter base model relative save path: ')\n","    fold_no = int(input('Enter the fold which the base model was validated: '))\n","\n","    model_save_dir = os.path.join(model_dir, model_name)\n","    \n","    base_model = tf.keras.models.load_model(base_model_save_path)\n","    base_model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["Create train and validation data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_train_vaild_data(spects, fold):\n","    train_spects = []\n","    valid_spects = None\n","    \n","    for i in range(5):\n","        if i + 1 != fold:\n","            train_spects.extend(spects[i])\n","        else:\n","            valid_spects = spects[i]\n","    \n","    train_df = pd.DataFrame(train_spects, columns=['feature', 'class'])\n","    valid_df = pd.DataFrame(valid_spects, columns=['feature', 'class'])\n","\n","    del train_spects\n","    del valid_spects\n","\n","    gc.collect()\n","\n","    X_train_cv = np.array(train_df['feature'].tolist())\n","    y_train_cv = np.array(train_df['class'].tolist())\n","    \n","    X_valid_cv = np.array(valid_df['feature'].tolist())\n","    y_valid_cv = np.array(valid_df['class'].tolist())\n","    \n","    return X_train_cv, X_valid_cv, y_train_cv, y_valid_cv"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8468,"status":"ok","timestamp":1699206322120,"user":{"displayName":"Dakshina Ranmal","userId":"07815065643648254868"},"user_tz":-330},"id":"33UB-4xW2L8j","outputId":"7a9a2411-80ae-40a7-d630-0050a47a2f29"},"outputs":[],"source":["X_train_cv, X_valid_cv, y_train_cv, y_valid_cv = get_train_vaild_data(spect_folds, fold_no)\n","\n","print(f'X_train_cv shape: {np.shape(X_train_cv)}')\n","print(f'y_train_cv shape: {np.shape(y_train_cv)}')\n","print(f'X_valid_cv shape: {np.shape(X_valid_cv)}')\n","print(f'y_valid_cv shape: {np.shape(y_valid_cv)}')"]},{"cell_type":"markdown","metadata":{},"source":["Create base model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Change according to the hyperparameters of the base model\n","\n","lr = 0.07619493236\n","best_optimizer = 'sgd'\n","batch_size = 32\n","epochs = 5\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr) if best_optimizer=='adam' else tf.keras.optimizers.SGD(learning_rate=lr)\n","base_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","base_model_loss, base_model_accuracy = base_model.evaluate(x=X_valid_cv,y=y_valid_cv)"]},{"cell_type":"markdown","metadata":{},"source":["### Weight pruning"]},{"cell_type":"markdown","metadata":{},"source":["Define weight pruning schedule and affected layers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Helper function uses `prune_low_magnitude` to make only the Selected layers train with pruning.\n","num_images = X_train_cv.shape[0]\n","end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n","\n","final_sparsity = float(input('Enter final sparsity: ')) # Example - 0.7\n","\n","def apply_pruning_to_layer(layer):\n","    pruning_params = {\n","          'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.0,\n","                                                                final_sparsity=final_sparsity,\n","                                                                begin_step=0,\n","                                                                end_step=end_step)\n","    }\n","\n","    if isinstance(layer, tf.keras.layers.Dense):\n","        return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n","    elif isinstance(layer, tf.keras.layers.Conv2D):\n","        return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n","    elif isinstance(layer, tf.keras.layers.BatchNormalization):\n","        return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n","\n","    return layer"]},{"cell_type":"markdown","metadata":{},"source":["Apply weight pruning mask to model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use `tf.keras.models.clone_model` to apply `apply_pruning_to_dense`\n","# to the layers of the model.\n","model_for_pruning = tf.keras.models.clone_model(\n","    base_model,\n","    clone_function=apply_pruning_to_layer,\n",")\n","\n","# `prune_low_magnitude` requires a recompile.\n","model_for_pruning.compile(\n","      optimizer=optimizer,\n","      loss='sparse_categorical_crossentropy',\n","      metrics=['accuracy']\n","      )\n","\n","model_for_pruning.summary()"]},{"cell_type":"markdown","metadata":{},"source":["Filter prune model by training it with weight pruning callback"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6515,"status":"ok","timestamp":1699206331982,"user":{"displayName":"Dakshina Ranmal","userId":"07815065643648254868"},"user_tz":-330},"id":"JYmHTZT_-NsM","outputId":"bc27992d-861c-468f-b00e-fe0d7002f448"},"outputs":[],"source":["with tf.device('/CPU:0'):\n","    logdir = os.path.join(model_save_dir, 'pruning_summaries')\n","\n","    if not os.path.exists(logdir):\n","        os.makedirs(logdir)\n","\n","    callbacks = [\n","        tfmot.sparsity.keras.UpdatePruningStep(),\n","        tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n","    ]\n","\n","    model_for_pruning.fit(X_train_cv, y_train_cv,\n","                        batch_size=batch_size, epochs=epochs, validation_data=(X_valid_cv, y_valid_cv),\n","                        callbacks=callbacks)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hsack4rblbkx"},"outputs":[],"source":["pruned_model_loss, pruned_model_accuracy = model_for_pruning.evaluate(x=X_valid_cv,y=y_valid_cv)\n","\n","print('Baseline test accuracy:', base_model_accuracy) \n","print('Pruned test accuracy:', pruned_model_accuracy)"]},{"cell_type":"markdown","metadata":{},"source":["### Save weight pruned model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n","\n","pruned_model_name = model_name + \"_weight_pruned_\" + str(final_sparsity) + \"_fold\" + str(fold_no)\n","\n","weight_pruned_model_save_path = os.path.join(model_save_dir, pruned_model_name + \".h5\")\n","\n","tf.keras.models.save_model(model_for_export, weight_pruned_model_save_path, include_optimizer=False)"]},{"cell_type":"markdown","metadata":{},"source":["Save weight pruned model as a Tensorflow Lite model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n","pruned_tflite_model = converter.convert()\n","\n","weight_pruned_tflite_model_save_path = os.path.join(model_save_dir, pruned_model_name + \".tflite\")\n","\n","with open(weight_pruned_tflite_model_save_path, 'wb') as f:\n","    f.write(pruned_tflite_model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_gzipped_model_size(file, model_type):\n","    # Returns size of gzipped model, in bytes.\n","\n","    zipped_file = os.path.join(model_save_dir, model_name + \"_\" + model_type + \".zip\")\n","    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n","        f.write(file)\n","\n","    return os.path.getsize(zipped_file)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(base_model_save_path, 'base')))\n","print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(weight_pruned_model_save_path, 'weight_pruned')))\n","print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(weight_pruned_tflite_model_save_path, '_weight_pruned_tflite')))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
